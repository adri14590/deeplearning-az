{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uab9OAbV8hYN"
   },
   "source": [
    "# Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "qukjDgj98kE4",
    "outputId": "ee6f4ce5-2b77-433c-f2bc-29fead6c2ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\aag\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aag\\anaconda3\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_lCXxqObOEc"
   },
   "source": [
    "# Instalar Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "ZuKBi9yzbOEd",
    "outputId": "112c8e47-f2d3-4390-d8e4-2bbed8ff91bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: theano in c:\\users\\aag\\anaconda3\\lib\\site-packages (1.0.5)\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --no-deps theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQVWgYPgbOEg"
   },
   "source": [
    "# Instalar Tensorflow y Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "lQlELtH5bOEg",
    "outputId": "430a74ac-094d-4a8b-935c-7dd333751fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\aag\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\aag\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aag\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install keras\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yFpBwmNz70v"
   },
   "source": [
    "# Redes Neuronales Artificales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8OxSXXSz-OP"
   },
   "source": [
    "# Cómo importar las librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edZX51YLzs59"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XfXlqtF0B58"
   },
   "source": [
    "# Importar el data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nnozsHsz_-N"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtzD5VD4bOEn"
   },
   "source": [
    "# Parte 1 - Pre procesado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsVEdPzf4XmV"
   },
   "source": [
    "# Codificar datos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v9CtwK834bjy"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "onehotencoder = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [1])],   \n",
    "    remainder='passthrough'                        \n",
    ")\n",
    "X = onehotencoder.fit_transform(X)\n",
    "# Ojo a la trampa de las variables ficticias: https://statologos.com/trampa-de-variables-ficticias/#:~:text=Trampa%20de%20variable%20ficticia%20%3A%20cuando,regresi%C3%B3n%20y%20los%20valores%20p.\n",
    "# La eliminamos quitando la primera columna\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Con la columna de sexo, que ahora es la 3, no hace falta hacer variables dummy, podemos directamente hacer el LabelEncoder (conversión de un género a 0 y otro a 1)\n",
    "# Si lo pensamos, al hacer el proceso de convertir a variables dummy hay que eliminar una variable ficticia por lo que en las variables que solo pueden tener dos \n",
    "# categorías no tiene sentido hacer el proceso de variables dummy\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X_2.fit_transform(X[:, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5AH_uCEz68rb"
   },
   "source": [
    "# Dividir el data set en conjunto de entrenamiento y conjunto de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeuAy8LI69vi"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfzLXHPwbOEt"
   },
   "source": [
    "# Escalado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8m2LCgz8bOEt"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgweTaJ67BOB"
   },
   "source": [
    "# Parte 2 - Construir la RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tm4Hg995bOEw"
   },
   "source": [
    "# Importar Keras y librerías adicionales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLEt5ni_bOEw"
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezfPlyegbOEy"
   },
   "source": [
    "# Inicializar la RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRmQjNVzbOEz"
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ML7H-iqsbOE1"
   },
   "source": [
    "# Añadir las capas de entrada y primera capa oculta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amkkZxnebOE1"
   },
   "outputs": [],
   "source": [
    "# Dense representa la sinapsis, conexión entre capas\n",
    "#   - Units es el número de nodos que queremos en la primera capa oculta. Un consejo para establecer el número de nodos en la capa oculta es hacer la media entre el \n",
    "#     número de nodos de entrada y de salida. Aquí tenemos (11 + 1) / 2 = 6\n",
    "#   - kernel_initializer se utiliza para inicializar los pesos. Se utiliza una distribución uniforme. Serán pequeños y cercanos a 0.\n",
    "#   - input_dim es el número de nodos de entrada que se tienen. input shape es un tensor, hay que especificarle el tamaño de la muestra y la dimensión de cada dato (en este caso 11)\n",
    "classifier.add(Dense(units = 6, kernel_initializer = \"uniform\", activation = \"relu\", input_dim = 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKoC5UOwbOE3"
   },
   "source": [
    "# Añadir la segunda capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTDhh_JibOE3"
   },
   "outputs": [],
   "source": [
    "# En la segunda capa no hace falta input_dim ya que al venir de la anterior ya sabe que sería 6.\n",
    "classifier.add(Dense(units = 6, kernel_initializer = \"uniform\",  activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvUfptEtbOE5"
   },
   "source": [
    "# Añadir la capa de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6C2x9RUGbOE5"
   },
   "outputs": [],
   "source": [
    "# - Al ser un resultado binario, se va o se queda del banco, solo habrá un nodo en la capa de salida.\n",
    "#   Si se quisiese clasificar en tres categorías: cliente activo, pasivo, neutro en el banco...tendríamos 3 nodos. Ya no se usaría la sigmoide por no ser la más adecuada...\n",
    "#   Deberíamos usar un escalón o un relu. Podríamos mantener la sigmoide pero probablemente tendríamos que usar softmax para que todas las probabilidades sumasen 1.\n",
    "# - En la última capa utilizamos una función de activación sigmoide para tener la probabilidad de que la predicción pertenezca a una clase u otra.\n",
    "classifier.add(Dense(units = 1, kernel_initializer = \"uniform\",  activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Je4JFqsbOE7"
   },
   "source": [
    "# Compilar la RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f89xXBswbOE7"
   },
   "outputs": [],
   "source": [
    "# Optimizer: es el algoritmo que se utiliza para encontrar el conjunto óptimo de pesos. Gradiente descendiente, gradiente descendiente estocástico, adam...\n",
    "# loss (función de pérdidas): función que minimiza el error entre la predicción de la red y el valor real. ordinary least squares (minimización diferencias al cuadrado),\n",
    "# Usamos la binary_crossentropy ya que es la más interesante para clasificación binaria.\n",
    "# metrics: son las métricas que el sistema va a evaluar y las que va a intentar aumentar de una iteración a la siguiente.\n",
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr34zpQrbOE9"
   },
   "source": [
    "# Ajustamos la RNA al Conjunto de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bwNUtZp7bOE9",
    "outputId": "d21731d6-ef82-47ed-bf24-1b22d0df0b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 762us/step - loss: 0.4880 - accuracy: 0.7954\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 743us/step - loss: 0.4286 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 931us/step - loss: 0.4228 - accuracy: 0.8011\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 755us/step - loss: 0.4166 - accuracy: 0.8257\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 740us/step - loss: 0.4119 - accuracy: 0.8313\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 775us/step - loss: 0.4085 - accuracy: 0.8307\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 758us/step - loss: 0.4058 - accuracy: 0.8338\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 859us/step - loss: 0.4039 - accuracy: 0.8360\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 727us/step - loss: 0.4027 - accuracy: 0.8338\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 751us/step - loss: 0.4013 - accuracy: 0.8341\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 938us/step - loss: 0.4008 - accuracy: 0.8354\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 896us/step - loss: 0.3994 - accuracy: 0.8329\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 896us/step - loss: 0.3989 - accuracy: 0.8354\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 840us/step - loss: 0.3983 - accuracy: 0.8341\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 942us/step - loss: 0.3981 - accuracy: 0.8345\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 741us/step - loss: 0.3974 - accuracy: 0.8344\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 822us/step - loss: 0.3976 - accuracy: 0.8351\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 788us/step - loss: 0.3968 - accuracy: 0.8371\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 725us/step - loss: 0.3968 - accuracy: 0.8334\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 728us/step - loss: 0.3961 - accuracy: 0.8347\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 712us/step - loss: 0.3960 - accuracy: 0.8353\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 780us/step - loss: 0.3959 - accuracy: 0.8336\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 829us/step - loss: 0.3956 - accuracy: 0.8349\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 802us/step - loss: 0.3959 - accuracy: 0.8345\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 732us/step - loss: 0.3957 - accuracy: 0.8342\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3952 - accuracy: 0.8341\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 783us/step - loss: 0.3951 - accuracy: 0.8353\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 771us/step - loss: 0.3947 - accuracy: 0.8339\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 721us/step - loss: 0.3950 - accuracy: 0.8378\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 741us/step - loss: 0.3944 - accuracy: 0.8375\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 957us/step - loss: 0.3951 - accuracy: 0.8363\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 767us/step - loss: 0.3946 - accuracy: 0.8345\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 970us/step - loss: 0.3945 - accuracy: 0.8355\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8349\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 929us/step - loss: 0.3947 - accuracy: 0.8338\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3943 - accuracy: 0.8355\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3944 - accuracy: 0.8349\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3948 - accuracy: 0.8350\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3943 - accuracy: 0.8336\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3941 - accuracy: 0.8374\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8363\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8356\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.8371\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3939 - accuracy: 0.8360\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 978us/step - loss: 0.3930 - accuracy: 0.8347\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3941 - accuracy: 0.8372\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3940 - accuracy: 0.8363\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3936 - accuracy: 0.8376\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3932 - accuracy: 0.8365\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3929 - accuracy: 0.8374\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3937 - accuracy: 0.8371\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3934 - accuracy: 0.8361\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8382\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3924 - accuracy: 0.8371\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8396\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3904 - accuracy: 0.8371\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 961us/step - loss: 0.3894 - accuracy: 0.8390\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 959us/step - loss: 0.3879 - accuracy: 0.8376\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3856 - accuracy: 0.8384\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3832 - accuracy: 0.8399\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3802 - accuracy: 0.8361\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 955us/step - loss: 0.3771 - accuracy: 0.8379\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3750 - accuracy: 0.8394\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 980us/step - loss: 0.3729 - accuracy: 0.8409\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3717 - accuracy: 0.8420\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 955us/step - loss: 0.3697 - accuracy: 0.8432\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 961us/step - loss: 0.3688 - accuracy: 0.8434\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3675 - accuracy: 0.8454\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3656 - accuracy: 0.8438\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 999us/step - loss: 0.3644 - accuracy: 0.8490\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8470\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3598 - accuracy: 0.8499\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3574 - accuracy: 0.8528\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 994us/step - loss: 0.3556 - accuracy: 0.8525\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3534 - accuracy: 0.8555\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3521 - accuracy: 0.8586\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3516 - accuracy: 0.8559\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 990us/step - loss: 0.3500 - accuracy: 0.8595\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 965us/step - loss: 0.3503 - accuracy: 0.8575\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3481 - accuracy: 0.8586\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3482 - accuracy: 0.8581\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 914us/step - loss: 0.3472 - accuracy: 0.8577\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 876us/step - loss: 0.3463 - accuracy: 0.8577\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 925us/step - loss: 0.3466 - accuracy: 0.8590\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 957us/step - loss: 0.3450 - accuracy: 0.8585\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 926us/step - loss: 0.3452 - accuracy: 0.8605\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 959us/step - loss: 0.3445 - accuracy: 0.8610\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3439 - accuracy: 0.8605\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3436 - accuracy: 0.8601\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8585\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.8594\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3428 - accuracy: 0.8605\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 930us/step - loss: 0.3423 - accuracy: 0.8616\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 997us/step - loss: 0.3423 - accuracy: 0.8596\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3422 - accuracy: 0.8596\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 992us/step - loss: 0.3414 - accuracy: 0.8596\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3409 - accuracy: 0.8630\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8599\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 927us/step - loss: 0.3417 - accuracy: 0.8615\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3411 - accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd0be28df0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size: si recordamos la teoría, una vez que hemos hecho una pasada se actualiza el conjunto de pasos. Aquí definimos el tamaño del lote.\n",
    "# epochs: definimos las veces que la red procesa todo el conjunto de datos para aprender.\n",
    "classifier.fit(X_train, y_train,  batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsUJ7kBnbOE_"
   },
   "source": [
    "# Parte 3 - Evaluar el modelo y calcular predicciones finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZWV9kiBbOFA"
   },
   "source": [
    "# Predicción de los resultados con el Conjunto de Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVzX_pIhbOFA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 710us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred  = classifier.predict(X_test)\n",
    "# Recordemos que las salidas son probabilidades, las convertimos a booleano\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0R6AD0bbOFD"
   },
   "source": [
    "# Elaborar una matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cv-193GvbOFD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1520   75]\n",
      " [ 200  205]]\n",
      "Precisión: 0.8625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(f\"Precisión: {(cm[0][0] + cm[1][1]) / cm.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Utiliza nuestro modelo de RNA para predecir si el cliente con la siguiente información abandonará el banco:\n",
    "\n",
    "*   Geografia: Francia\n",
    "*   Puntaje de crédito: 600\n",
    "*   Género masculino\n",
    "*   Edad: 40 años de edad\n",
    "*   Tenencia: 3 años.\n",
    "*   Saldo: $ 60000\n",
    "\n",
    "*   Número de productos: 2\n",
    "*   ¿Este cliente tiene una tarjeta de crédito? Sí\n",
    "*   ¿Es este cliente un miembro activo? Sí\n",
    "*   Salario estimado: $ 50000\n",
    "\n",
    "Entonces, ¿deberíamos decir adiós a ese cliente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "El cliente se queda con una probabilidad de 93.59163343906403%\n",
      "¿Deberíamos decir adiós a ese cliente? => No\n"
     ]
    }
   ],
   "source": [
    "# 1. Creamos los datos\n",
    "client_raw = pd.DataFrame([\n",
    "  { \n",
    "    \"CreditScore\": 600, \n",
    "    \"Geography\": 'France', \n",
    "    \"Gender\": 'Male', \n",
    "    \"Age\": 40, \n",
    "    \"Tenure\": 3, \n",
    "    \"Balance\": 60000, \n",
    "    \"NumOfProducts\": 2, \n",
    "    \"HasCrCard\": 1, \n",
    "    \"IsActiveMember\": 1, \n",
    "    \"EstimatedSalary\": 50000 \n",
    "  }\n",
    "])\n",
    "# 2. Transformamos los datos\n",
    "client_tr = onehotencoder.transform(client_raw.to_numpy())[:, 1:]\n",
    "client_tr[:,3] = labelencoder_X_2.transform(client_tr[:,3])\n",
    "\n",
    "# 3. Escalamos los datos\n",
    "client_tr = sc_X.transform(client_tr)\n",
    "\n",
    "# 4. Predecimos\n",
    "client_pred = classifier.predict(client_tr)\n",
    "print(f\"El cliente se queda con una probabilidad de {100 - client_pred[0][0] * 100}%\")\n",
    "client_pred = client_pred > 0.5\n",
    "\n",
    "# 5. Mostramos resultado\n",
    "result = \"Si\" if client_pred[0] else \"No\"\n",
    "print(f\"¿Deberíamos decir adiós a ese cliente? => {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ann.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
